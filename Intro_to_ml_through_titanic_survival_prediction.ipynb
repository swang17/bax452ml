{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "60c35bfb-359a-49bf-b119-bf5aeb9eceb2",
    "_uuid": "8027f6e7dee32dbd21d7cd461604303c9ef53c8a"
   },
   "source": [
    "__Reference__\n",
    "\n",
    "This notebook referenced the following Kaggle Kernels:\n",
    "-  [Nadin Tamer, Titanic Survival Predictions (Beginner)](https://www.kaggle.com/nadintamer/titanic-survival-predictions-beginner)\n",
    "-  [Omar El Gabry, A Journey through Titanic](https://www.kaggle.com/omarelgabry/a-journey-through-titanic)\n",
    "-  [Anisotropic, Introduction to Ensembling/Stacking in Python](https://www.kaggle.com/arthurtok/introduction-to-ensembling-stacking-in-python)\n",
    "- [Sina, Titanic best working Classifier](https://www.kaggle.com/sinakhorami/titanic-best-working-classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2190a220-ac34-4549-a422-4644db0ed4d0",
    "_uuid": "b91e80d8635e896b8851cd052e56afa614b20786"
   },
   "source": [
    "## Introduction to Machine Learning through Titanic Project\n",
    "\n",
    "###  Critical Steps\n",
    "1. Importing & Exploring Necessary Libraries\n",
    "2. Read in Data\n",
    "3. Feature Exploration\n",
    "4. Data Manipulation\n",
    "5. Running Machine Learning Algorithms\n",
    "6. Creating Submission File to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\n",
      "Collecting pandas\n",
      "  Downloading pandas-0.22.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (14.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 14.9MB 78kB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from pandas)\n",
      "Collecting pytz>=2011k (from pandas)\n",
      "  Downloading pytz-2017.3-py2.py3-none-any.whl (511kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 1.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.9.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from pandas)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from python-dateutil>=2->pandas)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-0.22.0 pytz-2017.3\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.8.1.tar.gz (178kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 3.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scipy (from seaborn)\n",
      "  Downloading scipy-1.0.0-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (16.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 16.7MB 61kB/s eta 0:00:011   21% |███████                         | 3.6MB 8.6MB/s eta 0:00:02    39% |████████████▊                   | 6.7MB 15.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib (from seaborn)\n",
      "  Downloading matplotlib-2.1.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (13.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 13.2MB 77kB/s  eta 0:00:01   27% |████████▊                       | 3.6MB 13.8MB/s eta 0:00:01    92% |█████████████████████████████▌  | 12.2MB 9.3MB/s eta 0:00:01    93% |█████████████████████████████▉  | 12.3MB 4.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from scipy->seaborn)\n",
      "Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->seaborn)\n",
      "  Downloading pyparsing-2.2.0-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 6.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib->seaborn)\n",
      "Requirement already satisfied: python-dateutil>=2.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib->seaborn)\n",
      "Requirement already satisfied: pytz in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib->seaborn)\n",
      "Collecting cycler>=0.10 (from matplotlib->seaborn)\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl\n",
      "Installing collected packages: scipy, pyparsing, cycler, matplotlib, seaborn\n",
      "  Running setup.py install for seaborn ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed cycler-0.10.0 matplotlib-2.1.1 pyparsing-2.2.0 scipy-1.0.0 seaborn-0.8.1\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages\n",
      "Requirement already satisfied: pytz in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: six>=1.10 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: python-dateutil>=2.0 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from matplotlib)\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz\n",
      "Collecting scikit-learn (from sklearn)\n",
      "  Downloading scikit_learn-0.19.1-cp36-cp36m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (7.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 7.6MB 116kB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: scikit-learn, sklearn\n",
      "  Running setup.py install for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed scikit-learn-0.19.1 sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy\n",
    "!pip3 install pandas\n",
    "!pip3 install seaborn\n",
    "!pip3 install matplotlib\n",
    "!pip3 install sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bdae2086-dbb9-449f-a796-ecd9b5174f27",
    "_uuid": "2ac5e8e671a54af34d224820a256964e81a74a7c"
   },
   "source": [
    "# 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "04cf6722-386d-417b-9826-a46b9ffa9fe4",
    "_uuid": "d45f4a58c6f3054f9da697327c465424f9e7330b"
   },
   "outputs": [],
   "source": [
    "# Data Analysis Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data Visualization Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine Learning Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1aeade1a-5daa-479e-bf26-1e7686b2d580",
    "_uuid": "6f2317efff784729d6faff4c5d7f7b1b78c1c931"
   },
   "source": [
    "# 2. Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_cell_guid": "176983e1-532c-4ded-a506-eb6ed27e33d0",
    "_uuid": "46138d9e659b367f6f4fc0578164a3cb4277052c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "02f8a5dc-1fc3-4a33-81a6-85f3e63cf39c",
    "_uuid": "e9ddcb75310e609f5ece7ed3fd2f19cbad94c630"
   },
   "source": [
    "# 3. Feature Exploration\n",
    "\n",
    "In this step, we will get a basic sense of the data and visualize the features to figure out which ones are relevant for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "30262269-6ba4-4f14-9b04-a2978669ac33",
    "_uuid": "9ca5234ee67b46bb601fb8f60a5af7e025a92a3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wright, Mr. George</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113807</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>573</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Flynn, Mr. John Irwin (\"Irving\")</td>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17474</td>\n",
       "      <td>26.3875</td>\n",
       "      <td>E25</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Gilnagh, Miss. Katherine \"Katie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35851</td>\n",
       "      <td>7.7333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sheerlinck, Mr. Jan Baptist</td>\n",
       "      <td>male</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345779</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>West, Miss. Constance Mirium</td>\n",
       "      <td>female</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>C.A. 34651</td>\n",
       "      <td>27.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                              Name     Sex  \\\n",
       "555          556         0       1                Wright, Mr. George    male   \n",
       "572          573         1       1  Flynn, Mr. John Irwin (\"Irving\")    male   \n",
       "156          157         1       3  Gilnagh, Miss. Katherine \"Katie\"  female   \n",
       "81            82         1       3       Sheerlinck, Mr. Jan Baptist    male   \n",
       "58            59         1       2      West, Miss. Constance Mirium  female   \n",
       "\n",
       "      Age  SibSp  Parch      Ticket     Fare Cabin Embarked  \n",
       "555  62.0      0      0      113807  26.5500   NaN        S  \n",
       "572  36.0      0      0    PC 17474  26.3875   E25        S  \n",
       "156  16.0      0      0       35851   7.7333   NaN        Q  \n",
       "81   29.0      0      0      345779   9.5000   NaN        S  \n",
       "58    5.0      1      2  C.A. 34651  27.7500   NaN        S  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A basic look at the training data\n",
    "train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "cd96a59f-fdca-492d-8bf0-05612adfa019",
    "_uuid": "52e13714e0011658e5c7a60a1c05012978290b5d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>204</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>681</td>\n",
       "      <td>NaN</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Johanson, Mr. Jakob Alfred</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.204208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>49.693429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.910400</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.454200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>512.329200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PassengerId    Survived      Pclass                        Name   Sex  \\\n",
       "count    891.000000  891.000000  891.000000                         891   891   \n",
       "unique          NaN         NaN         NaN                         891     2   \n",
       "top             NaN         NaN         NaN  Johanson, Mr. Jakob Alfred  male   \n",
       "freq            NaN         NaN         NaN                           1   577   \n",
       "mean     446.000000    0.383838    2.308642                         NaN   NaN   \n",
       "std      257.353842    0.486592    0.836071                         NaN   NaN   \n",
       "min        1.000000    0.000000    1.000000                         NaN   NaN   \n",
       "25%      223.500000    0.000000    2.000000                         NaN   NaN   \n",
       "50%      446.000000    0.000000    3.000000                         NaN   NaN   \n",
       "75%      668.500000    1.000000    3.000000                         NaN   NaN   \n",
       "max      891.000000    1.000000    3.000000                         NaN   NaN   \n",
       "\n",
       "               Age       SibSp       Parch    Ticket        Fare        Cabin  \\\n",
       "count   714.000000  891.000000  891.000000       891  891.000000          204   \n",
       "unique         NaN         NaN         NaN       681         NaN          147   \n",
       "top            NaN         NaN         NaN  CA. 2343         NaN  C23 C25 C27   \n",
       "freq           NaN         NaN         NaN         7         NaN            4   \n",
       "mean     29.699118    0.523008    0.381594       NaN   32.204208          NaN   \n",
       "std      14.526497    1.102743    0.806057       NaN   49.693429          NaN   \n",
       "min       0.420000    0.000000    0.000000       NaN    0.000000          NaN   \n",
       "25%      20.125000    0.000000    0.000000       NaN    7.910400          NaN   \n",
       "50%      28.000000    0.000000    0.000000       NaN   14.454200          NaN   \n",
       "75%      38.000000    1.000000    0.000000       NaN   31.000000          NaN   \n",
       "max      80.000000    8.000000    6.000000       NaN  512.329200          NaN   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  \n",
       "mean        NaN  \n",
       "std         NaN  \n",
       "min         NaN  \n",
       "25%         NaN  \n",
       "50%         NaN  \n",
       "75%         NaN  \n",
       "max         NaN  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summary of the training data\n",
    "train.describe(include = \"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "06ce185f-1c5d-4bd2-b2aa-d43f26a14bef",
    "_uuid": "3847162e1c8255083825854642e309e9df4b5170",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get a clearer understanding of data types and missing values\n",
    "train.info()\n",
    "print('***************************************************')\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "94c8ddee-4f94-49c4-a3cb-36b088c396fa",
    "_uuid": "79c8b3d5815a1dc714ec875e6a4fe31cd2656a7d"
   },
   "source": [
    "## 3.1 Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3eeb9f9b-62b7-4b80-8c69-bcd184ad8303",
    "_uuid": "b7ae451697e95c7c802730836a3e7fd01cda86eb",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore if survival rate depends on passenger class\n",
    "sns.barplot(x = \"Pclass\", y = \"Survived\", data = train)\n",
    "train[[\"Pclass\", \"Survived\"]].groupby([\"Pclass\"], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79d1531c-195e-48cf-9a82-01f4c1785663",
    "_uuid": "9a432f593be2d1eb6c94df0dfd0314dec7bfce98"
   },
   "source": [
    "There seems to be a significant difference in survival rate for passengers in different classes. This feature should go into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cb051c90-c0c7-40c8-a94d-a35c8f6cc97a",
    "_uuid": "ceb81a17ac17a989aba53e1d7edac74ebef39825"
   },
   "source": [
    "## 3.2 Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fbf527ed-25bc-4ebe-a217-2c564c4380ad",
    "_uuid": "890f5810b8e499cd71e4dbd25f60c043900cf646",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Explore if survival rate depends on passenger gender\n",
    "sns.barplot(x = \"Sex\", y = \"Survived\", data = train)\n",
    "train[[\"Sex\", \"Survived\"]].groupby([\"Sex\"], as_index = False).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5bf389bd-c909-4b27-b994-60923d974601",
    "_uuid": "9b28a0f2aeac9e4d4833731c1243b91fb997afe6"
   },
   "source": [
    "Sex should definitely go into the model as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "71aea022-8031-4cb6-949c-3a96058a6eb4",
    "_uuid": "c7262691a4d470b5511d2c5e85818d61e91a0de9"
   },
   "source": [
    "## 3.3 Age "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e14f67f9-7bc8-49a0-866e-9dc52382b851",
    "_uuid": "03ccafe913df52a63571e8170ed686a13aa67fdf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age is a continuous variable with 20% of the data missing. \n",
    "# We will first look at the distribution\n",
    "sns.distplot(train[\"Age\"].dropna(), bins = 70, kde = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "542506f9-d37e-40af-924d-253de0d4a6be",
    "_uuid": "a9258526982acf6c4e57e410564131a626caab4d"
   },
   "source": [
    "- Age is not normally distributed so we cannot simply generate random numbers following a normal distribution to fill in the missing numbers. \n",
    "- Instead of treating age as a continuous variable, it might be better to categorize age intervals since one year difference in age would probably not determine if the person survive.\n",
    "- In the next section, we will come up ways to fill in the missing value and categorize age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5bafe9d0-0852-42cc-beab-96ae22ec4cc9",
    "_uuid": "e98c051920c1236f618cfbd725e6a803606ed1cf"
   },
   "source": [
    "## 3.3 SibSp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "72a96cd7-98cf-4f73-92ba-0bb55bd0e5dc",
    "_uuid": "c84fe879b18428d08f96e6d24e090b1682df2da3",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Explore if survival rate depends on the number of siblings/spouses abroad the Titanic\n",
    "sns.barplot(x = \"SibSp\", y = \"Survived\", data = train)\n",
    "sibsp = pd.DataFrame()\n",
    "sibsp[\"Survived Mean\"] = train[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index = False).mean()[\"Survived\"]\n",
    "sibsp[\"Count\"] = train[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index = False).count()[\"Survived\"]\n",
    "sibsp[\"STD\"] = train[[\"SibSp\", \"Survived\"]].groupby([\"SibSp\"], as_index = False).std()[\"Survived\"]\n",
    "print(sibsp)\n",
    "train[(train[\"SibSp\"] == 5)|(train[\"SibSp\"] == 8)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e21e89e2-0b3a-40c6-8db9-1652cc9d4a36",
    "_uuid": "62e54360d40986e75a02986e82c2e1ab9a3d017a"
   },
   "source": [
    "- In the next step, we will group \"SibSp\" into [0, 1, 2 or more]\n",
    "- It is surprising that none of the members in the two families with 5 and 8 SibSp survived. Looking at the available \"Age\" data points, it seems that most of them are kids. It would be a good idea to fill in the rest ages as \"teenagers\" or \"kids\". However, there are only 7 records that needs to be filled in in this way so in this analysis, we will not treat them differently. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "66df6041-8ffb-4750-8223-8aa9a881b2d6",
    "_uuid": "dd6ec8cd30667ffa2e69fd935380d4f5ee516de3"
   },
   "source": [
    "## 3.4 Parch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6698d603-866d-4708-b49a-efc707260138",
    "_uuid": "c2e61412427e739ff3d751009e86d6ddb57ac53d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore if survival rate depends on the number of parents/children abroad the Titanic\n",
    "sns.barplot(x = \"Parch\", y = \"Survived\", data = train)\n",
    "sibsp[\"Survived Mean\"] = train[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index = False).mean()[\"Survived\"]\n",
    "sibsp[\"Count\"] = train[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index = False).count()[\"Survived\"]\n",
    "sibsp[\"STD\"] = train[[\"Parch\", \"Survived\"]].groupby([\"Parch\"], as_index = False).std()[\"Survived\"]\n",
    "print(sibsp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d3c29a8-bc00-4664-8c05-8ba4f73dc261",
    "_uuid": "d9c78586c630c6509208dac25ec7c9aacbe18175"
   },
   "source": [
    "- In the next step, we will group \"Parch\" into [0, 1, 2 or more]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5c399d37-ccf0-4dae-aee9-24ade24f3ba5",
    "_uuid": "524cf03901849babe59994d47e0b6f034cbc3c07"
   },
   "source": [
    "## 3.5 Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "2e1d15d8-88d1-4ec0-a8ee-46775f7b7c2b",
    "_uuid": "07734e4ea4c2ea193a13546d52feaed7e745e8c3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# See the distribution of Fare\n",
    "#sns.distplot(train[\"Fare\"][train[\"Pclass\"]==1].dropna(), bins = 10, kde = False)\n",
    "print(train[[\"Fare\", \"Survived\"]].dropna().groupby([\"Survived\"]).count())\n",
    "fare_hist = sns.FacetGrid(train, col=\"Survived\")\n",
    "fare_hist = fare_hist.map(plt.hist, \"Fare\")\n",
    "\n",
    "train[[\"Fare\", \"Survived\"]].dropna().groupby([\"Survived\"]).median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7ddf2488-eff8-42ab-9623-a66b228a1b33",
    "_uuid": "ff24344dbd256e4a3988c3b9b6b7132d9bb58317"
   },
   "source": [
    "- The outputs above indicate that the distribution of fare for the group who survived and the group who did not is different. So we will include fare in the model.\n",
    "- We will also categorize fare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "db73c384-f632-4146-9b67-dcf20c6b76d9",
    "_uuid": "b2c7db3c79ee2d79719d47c44c1bd771d82b3cf8"
   },
   "source": [
    "## 3.6 Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "93c12506-a7a6-4f23-a8ac-c3ff56a3298f",
    "_uuid": "f343cf2b42c33b556040784205eb4fa2d1a468e5",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# There are many missing values in this colomn\n",
    "(train[\"Survived\"][train[\"Cabin\"].isnull()].count())/(train[\"Cabin\"].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d5827104-c8b8-42af-a484-4eef0de211f7",
    "_uuid": "5448f0174094179e793f53d6a2d3880a3278672a"
   },
   "source": [
    "- Since there are much more missing values than available values, we will leave this variable out from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "336d68c5-248c-4e89-bc42-44ba5dfa1d98",
    "_uuid": "24e0c6234df896784fbf462d526e8be018e1d643"
   },
   "source": [
    "## 3.7 Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "031c1171-7f96-46a7-b10c-63ac1ea1369e",
    "_uuid": "67809fd8f3587a1da45195cfbd4752e8c30430f7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Explore if survival rate depends on the port passenger embarked\n",
    "sns.barplot(x = \"Embarked\", y = \"Survived\", data = train)\n",
    "train[[\"Survived\", \"Embarked\"]].groupby([\"Embarked\"]).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "39261fb7-be85-41f0-8877-c85070c8df94",
    "_uuid": "d16bffe521ae7c13d0f91f6505f091f349253be9"
   },
   "source": [
    "- We will keep this variable in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dc53960a-1b96-4c2d-bbcc-c9b0401ffdf7",
    "_uuid": "c8a4fa416e49fddc89ac9d66a41555ab507810a4"
   },
   "source": [
    "## Insights from Feature Exploration & Next Steps\n",
    "- Some variables may not have valuable information and can be dropped from the dataset.\n",
    "- Missing values in both the training dataset and testing dataset should be addressed.\n",
    "- Continuous variables should be categorized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d7a9b57a-a507-4bb2-9da8-4126384ba4cb",
    "_uuid": "cc7fc2962acef7bb6967c2eab0aa09356ff2dc70",
    "collapsed": true
   },
   "source": [
    "# 4. Data Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "894aaf5b-108e-4858-b3b5-ea7b4ff6b4c9",
    "_uuid": "af76354722c2a68e55ab9f2378e8d755fd699f65",
    "collapsed": true
   },
   "source": [
    "## 4.1 Dropping Unnecessary Variables\n",
    "\n",
    "From the outputs above, we get a basic sense of the variables and it is intuitive that \"PassengerId\", \"Name\"and \"Ticket\" are not likely to be valuable for the analysis. Therefore, we will drop these variables from both the training and testing dataset. \n",
    "\n",
    "From the summary statistics, we also realize that the column \"cabin\" has too many missing values to draw information from. We will also exclude this column from the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "38178bdc-d2c1-4332-9370-eb9c7fff7567",
    "_uuid": "7221ec4516c5bc09f8bb288dc2b2a6cc0f90240d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PassengerId = test['PassengerId']\n",
    "train = train.drop([\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"], axis = 1)\n",
    "test = test.drop([\"PassengerId\",\"Name\", \"Ticket\", \"Cabin\"], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4ce16fd6-ea77-4ff4-a8f5-c16fef6e5f54",
    "_uuid": "856119fc24971160edd52990a27a6fc6bc508071",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train.info()\n",
    "#print('***************************************************')\n",
    "#test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "fdd086a3-b227-4291-b91f-c24336267055",
    "_uuid": "30386a4e85ba80bfba7263814856d990e12ffa35"
   },
   "source": [
    "## 4.2 Dealing with Missing Values\n",
    "\n",
    "There are two variabels with missing values in the training dataset: \"Age\" and \"Embarked\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "dd662773-8912-4bd4-8148-d9cc829d8232",
    "_uuid": "dbdad4f6998a115f21db9765ec4f9aacfa5eb9e1",
    "collapsed": true
   },
   "source": [
    " ## *4.2.1 Embarked -- categorical data* \n",
    " \n",
    " ### It's common to replace missing values of a categorical variable with mode. We will find the count for each unique values and replace is with the most appeared value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "60c1de71-1e21-46be-bd47-969d63612054",
    "_uuid": "d600bf75aa41c7f4615147418faf5403ca7d9324",
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(train[\"Embarked\"].unique())\n",
    "print(train.groupby([\"Embarked\"])[\"Survived\"].count().reset_index())\n",
    "train[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")\n",
    "train.groupby([\"Embarked\"])[\"Survived\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c2349fa0-4e1b-4297-a58d-a539951e016e",
    "_uuid": "8929cf9e82d1803fd8d4bab08d7d7be4669eda4c"
   },
   "source": [
    "## *4.2.2 Age*\n",
    "\n",
    "### About 20% of the \"Age\" column is missing. As inspied by *A Journey through Titanic*, we will replace missing values with random numbers between (mean - std) and (mean + std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "88750c9d-64a8-448d-af4a-be1fb6f3e3e5",
    "_uuid": "6f833b3910636d62efe3eb4244275a158cf90730",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate mean and standard deviation of \"Age\" column\n",
    "train_mean = train[\"Age\"].mean()\n",
    "train_std = train[\"Age\"].std()\n",
    "test_mean = test[\"Age\"].mean()\n",
    "test_std = test[\"Age\"].std()\n",
    "\n",
    "# Count missing values\n",
    "count_na_train = train[\"Age\"].isnull().sum()\n",
    "count_na_test = test[\"Age\"].isnull().sum()\n",
    "\n",
    "# generate random numbers\n",
    "np.random.seed(66)\n",
    "train_rand = np.random.randint(train_mean - train_std, train_mean + train_std, size = count_na_train)\n",
    "test_rand = np.random.randint(test_mean - test_std, test_mean + test_std, size = count_na_test)\n",
    "\n",
    "# Fill missing values with random numbers\n",
    "train[\"Age\"][np.isnan(train[\"Age\"])] = train_rand\n",
    "test[\"Age\"][np.isnan(test[\"Age\"])] = test_rand\n",
    "\n",
    "# Convert into int\n",
    "train[\"Age\"] = train[\"Age\"].astype(int)\n",
    "test[\"Age\"] = test[\"Age\"].astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "89e4ff83-d669-4405-93da-79374a0b45b8",
    "_uuid": "53a7ff2038de700501ada47ba6e05afe2620f873"
   },
   "source": [
    "## *4.2.3 Fare*\n",
    "\n",
    "### There is one missing value for fare in the test data. We will simply replace it with the median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "03ec0afd-0dcd-40f9-9ef5-a823548ee94a",
    "_uuid": "dd684aaa618d7a19f8a644bc65cf16eac2c52530",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[\"Fare\"] = test[\"Fare\"].fillna(test[\"Fare\"].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "78055fbe-9384-49e6-a62b-1d884c2a157f",
    "_uuid": "79198c77c55e2ad1433fd9f707dd1e404cf34938",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Confirm that all missing values are taken care of\n",
    "#train.info()\n",
    "#print('***************************************************')\n",
    "#test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ea616b86-ce91-4cac-bd78-a6428052d1bf",
    "_uuid": "d87c10fac934a012f32eecf8e39ad796d83acbaf"
   },
   "source": [
    "## 4.3 Categorize Numeric Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "19b095df-e109-4f44-abb3-dde3b4be4f3f",
    "_uuid": "2ea4284b8093d2de6f2438f3618f8a51d17f5c0a"
   },
   "source": [
    "## 4.3.1 Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e8a8fc6f-1d42-481a-9818-ade470f77635",
    "_uuid": "e6714e175407f6cc96591af0a7a1fa50a302f350",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map Age to categorical groups\n",
    "train.loc[train[\"Age\"] <= 3, \"age_c\"] = \"Infant & Toddler\"\n",
    "train.loc[(train[\"Age\"] > 3)&(train[\"Age\"] <= 12), \"age_c\"] = \"Young Teenage\"\n",
    "train.loc[(train[\"Age\"] <= 18)&(train[\"Age\"] > 12), \"age_c\"] = \"Teenager\"\n",
    "train.loc[(train[\"Age\"] > 18)&(train[\"Age\"] <= 25), \"age_c\"] = \"Young Adult\"\n",
    "train.loc[(train[\"Age\"] <= 50)&(train[\"Age\"] > 25), \"age_c\"] = \"Adult\"\n",
    "train.loc[(train[\"Age\"] > 50)&(train[\"Age\"] <= 65), \"age_c\"] = \"Middle-aged\"\n",
    "train.loc[(train[\"Age\"] > 65), \"age_c\"] = \"Senior\"\n",
    "\n",
    "test.loc[test[\"Age\"] <= 3, \"age_c\"] = \"Infant & Toddler\"\n",
    "test.loc[(test[\"Age\"] > 3)&(test[\"Age\"] <= 12), \"age_c\"] = \"Young Teenage\"\n",
    "test.loc[(test[\"Age\"] <= 18)&(test[\"Age\"] > 12), \"age_c\"] = \"Teenager\"\n",
    "test.loc[(test[\"Age\"] > 18)&(test[\"Age\"] <= 25), \"age_c\"] = \"Young Adult\"\n",
    "test.loc[(test[\"Age\"] <= 50)&(test[\"Age\"] > 25), \"age_c\"] = \"Adult\"\n",
    "test.loc[(test[\"Age\"] > 50)&(test[\"Age\"] <= 65), \"age_c\"] = \"Middle-aged\"\n",
    "test.loc[(test[\"Age\"] > 65), \"age_c\"] = \"Senior\"\n",
    "\n",
    "train[[\"age_c\",\"Survived\"]].groupby([\"age_c\"]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "927b41de71618e2e5fdca8cfbd49ff5a248667c7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set up two new dataframes for the final model\n",
    "m_train = train\n",
    "m_test = test\n",
    "\n",
    "#m_train.info()\n",
    "#print('***************************************************')\n",
    "#m_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fbc60848-6e5b-4d95-9940-d810ea20bb98",
    "_uuid": "2c3219d23656fb27b5c689535b7179f706f8aee9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate Dummy Variable for Age\n",
    "# Dropped the first one to avoid multicollinearity\n",
    "age_dummy_train = pd.get_dummies(train[\"age_c\"], drop_first = True)\n",
    "age_dummy_test = pd.get_dummies(test[\"age_c\"], drop_first = True)\n",
    "\n",
    "# Concatenate Age dummy with the original training dataset\n",
    "m_train = pd.concat([m_train, age_dummy_train], axis = 1)\n",
    "m_test = pd.concat([m_test, age_dummy_test], axis = 1)\n",
    "\n",
    "# Drop original Age and age_c\n",
    "m_train = m_train.drop([\"age_c\", \"Age\"], axis = 1)\n",
    "m_test = m_test.drop([\"age_c\", \"Age\"], axis = 1)\n",
    "\n",
    "m_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "238c212f-8d04-49f3-8ee7-d645f7aca22e",
    "_uuid": "f6ef8e1bb10c2992e9398b2725292c42a5151c8c",
    "collapsed": true
   },
   "source": [
    "## 4.3.2 SibSp\n",
    "\n",
    "Categorize into 0,1,2 or more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8645a04a76ac1294e41789c9377140a5a04b3f55",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map SibSp into categories\n",
    "train.loc[train[\"SibSp\"] == 0, \"sib_c\"] = \"None\"\n",
    "train.loc[train[\"SibSp\"] == 1, \"sib_c\"] = \"One\"\n",
    "train.loc[train[\"SibSp\"] >1 , \"sib_c\"] = \"2 or More\"\n",
    "\n",
    "test.loc[test[\"SibSp\"] == 0, \"sib_c\"] = \"None\"\n",
    "test.loc[test[\"SibSp\"] == 1, \"sib_c\"] = \"One\"\n",
    "test.loc[test[\"SibSp\"] >1 , \"sib_c\"] = \"2 or More\"\n",
    "\n",
    "# Generate Dummy Variable\n",
    "sib_dummy_train = pd.get_dummies(train[\"sib_c\"], drop_first = True)\n",
    "sib_dummy_test = pd.get_dummies(test[\"sib_c\"], drop_first = True)\n",
    "\n",
    "\n",
    "# Append sib_dummy to m-train\n",
    "m_train = pd.concat([m_train, sib_dummy_train], axis = 1)\n",
    "m_train = m_train.drop([\"SibSp\"], axis = 1)\n",
    "\n",
    "m_test = pd.concat([m_test, sib_dummy_test], axis = 1)\n",
    "m_test = m_test.drop([\"SibSp\"], axis = 1)\n",
    "\n",
    "m_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "61de721af7c089f53bcfd52d0c0057b833aa3dbc"
   },
   "source": [
    "## 4.3.3 Parch\n",
    "\n",
    "Categorize into 0,1, 2 and more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4d36a9de288fceada727848fbd0471f77a4d3c63",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map Parch into categories\n",
    "train.loc[train[\"Parch\"] == 0, \"pc_c\"] = \"None_pc\"\n",
    "train.loc[train[\"Parch\"] == 1, \"pc_c\"] = \"One_pc\"\n",
    "train.loc[train[\"Parch\"] >1 , \"pc_c\"] = \"2 or More_pc\"\n",
    "\n",
    "test.loc[test[\"Parch\"] == 0, \"pc_c\"] = \"None_pc\"\n",
    "test.loc[test[\"Parch\"] == 1, \"pc_c\"] = \"One_pc\"\n",
    "test.loc[test[\"Parch\"] >1 , \"pc_c\"] = \"2 or More_pc\"\n",
    "\n",
    "# Generate Dummy Variable\n",
    "pc_dummy_train = pd.get_dummies(train[\"pc_c\"], drop_first = True)\n",
    "pc_dummy_test = pd.get_dummies(test[\"pc_c\"], drop_first = True)\n",
    "\n",
    "\n",
    "# Append sib_dummy to m-train/m-test\n",
    "m_train = pd.concat([m_train, pc_dummy_train], axis = 1)\n",
    "m_train = m_train.drop([\"Parch\"], axis = 1)\n",
    "\n",
    "m_test = pd.concat([m_test, pc_dummy_test], axis = 1)\n",
    "m_test = m_test.drop([\"Parch\"], axis = 1)\n",
    "\n",
    "m_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c6fb0da7d398e4039d4f96acac24389dfd82c416"
   },
   "source": [
    "## 4.3.4 Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec759d3576071be1e5509d0f20203488c422bcd8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map fare values into categories\n",
    "train[\"fare_c\"] = pd.qcut(train[\"Fare\"], 4, labels = [\"fare25%\", \"fare50%\", \"fare75%\",\"fare100%\"])\n",
    "test[\"fare_c\"] = pd.qcut(test[\"Fare\"], 4, labels = [\"fare25%\", \"fare50%\", \"fare75%\",\"fare100%\"])\n",
    "\n",
    "# Generate dummy variables for both train and test\n",
    "fare_dummy_train = pd.get_dummies(train[\"fare_c\"], drop_first = True)\n",
    "fare_dummy_test = pd.get_dummies(test[\"fare_c\"], drop_first = True)\n",
    "\n",
    "# Append dummy variables to the original data frames\n",
    "m_train = pd.concat([m_train, fare_dummy_train], axis = 1)\n",
    "m_train = m_train.drop([\"Fare\"], axis = 1)\n",
    "\n",
    "m_test = pd.concat([m_test, fare_dummy_test], axis = 1)\n",
    "m_test = m_test.drop([\"Fare\"], axis = 1)\n",
    "\n",
    "m_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "22d97180-dea3-4bb2-bea4-9b38ef482626",
    "_uuid": "5704216689edf8769509ce0b67b0ff5bfa71cbf6"
   },
   "source": [
    "## 4.4 Assign numerical values to categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "83e13901-5f9e-4ab4-bd1b-864030c27a36",
    "_uuid": "ef468cd647223b5961f79ef667f0c90589eeec34",
    "collapsed": true
   },
   "source": [
    "## 4.4.1 Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d55ff971-921a-4fcc-8b2e-6d47574545e6",
    "_uuid": "d48efc5837c2bb8bda39ea3bbbf915ae3dad3112",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate dummy variables for both train and test\n",
    "sex_dummy_train = pd.get_dummies(train[\"Sex\"], drop_first = True)\n",
    "sex_dummy_test = pd.get_dummies(test[\"Sex\"], drop_first = True)\n",
    "\n",
    "# Append dummy variables to the original data frames\n",
    "m_train = pd.concat([m_train, sex_dummy_train], axis = 1)\n",
    "m_train = m_train.drop([\"Sex\"], axis = 1)\n",
    "\n",
    "m_test = pd.concat([m_test, sex_dummy_test], axis = 1)\n",
    "m_test = m_test.drop([\"Sex\"], axis = 1)\n",
    "\n",
    "m_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0abe83f655f29d7cadfd4f45840ab3738f2789a9"
   },
   "source": [
    "## 4.4.2 Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "deb7fd8cf8f0bfda950f5bf77b79fd34742f952d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate dummy variables for both train and test\n",
    "emk_dummy_train = pd.get_dummies(train[\"Embarked\"], drop_first = True)\n",
    "emk_dummy_test = pd.get_dummies(test[\"Embarked\"], drop_first = True)\n",
    "\n",
    "# Append dummy variables to the original data frames\n",
    "m_train = pd.concat([m_train, emk_dummy_train], axis = 1)\n",
    "m_train = m_train.drop([\"Embarked\"], axis = 1)\n",
    "\n",
    "m_test = pd.concat([m_test, emk_dummy_test], axis = 1)\n",
    "m_test = m_test.drop([\"Embarked\"], axis = 1)\n",
    "\n",
    "m_train.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "15d7274fc88c14336e67de570b7f541b839512bd"
   },
   "source": [
    "## 4.4.3 Pclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9c706c6c0b21d31338dd920be7ab15a96247278a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map Parch into categories\n",
    "train.loc[train[\"Pclass\"] == 1, \"class_c\"] = \"class1\"\n",
    "train.loc[train[\"Pclass\"] == 2, \"class_c\"] = \"class2\"\n",
    "train.loc[train[\"Pclass\"] == 3, \"class_c\"] = \"class3\"\n",
    "\n",
    "test.loc[train[\"Pclass\"] == 1, \"class_c\"] = \"class1\"\n",
    "test.loc[train[\"Pclass\"] == 2, \"class_c\"] = \"class2\"\n",
    "test.loc[train[\"Pclass\"] == 3, \"class_c\"] = \"class3\"\n",
    "\n",
    "# Generate dummy variables for both train and test\n",
    "class_dummy_train = pd.get_dummies(train[\"class_c\"], drop_first = True)\n",
    "class_dummy_test = pd.get_dummies(test[\"class_c\"], drop_first = True)\n",
    "\n",
    "# Append dummy variables to the original data frames\n",
    "m_train = pd.concat([m_train, class_dummy_train], axis = 1)\n",
    "m_train = m_train.drop([\"Pclass\"], axis = 1)\n",
    "\n",
    "m_test = pd.concat([m_test, class_dummy_test], axis = 1)\n",
    "m_test = m_test.drop([\"Pclass\"], axis = 1)\n",
    "\n",
    "m_train.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "790c2a3688199104f769fa4bbe2c7329af89ab21",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check dataset status before modelling\n",
    "train.info()\n",
    "print('***************************************************')\n",
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "db01835ee14d216ec93e9bded8edf575bc6e5d0c"
   },
   "source": [
    "# 5. Running Machine Learning Algorithms\n",
    "\n",
    "The datasets are finally ready for modeling!!!\n",
    "\n",
    "We will explore the following models:\n",
    "- Gaussian Naive Bayes\n",
    "- Logistics Regression\n",
    "- Support Vector Machine\n",
    "- Decision Tree Classifier\n",
    "- Random Forest Classifier\n",
    "- K-Nearest Neighbors\n",
    "\n",
    "* Note that all parameters are set as default as of 1/10/2018; To be adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2dfae9ba8aed8b30e9533c4838a2ea471f31908e",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# As inspired by Nadin, we will use 80% of the data for training,\n",
    "# and the rest 20% to test the accuracy of the model\n",
    "\n",
    "predictors = m_train.drop([\"Survived\"], axis = 1)\n",
    "target = m_train[\"Survived\"]\n",
    "x_train, x_val, y_train, y_val = train_test_split(predictors, target, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee8545681249bbbc5446c1dd329b6ea96e49b0a5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gaussian Naive Bayes\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(x_train, y_train)\n",
    "# y_pred = gaussian.predict(x_val)\n",
    "acc_gaussian = gaussian.score(x_val, y_val)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f6d2ed7a076b2d5c18904a61ca10bd1afd30b76",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(x_train, y_train)\n",
    "#y_pred = logreg.predict(x_val)\n",
    "acc_logreg = logreg.score(x_val, y_val)\n",
    "acc_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9d0f4edb52ec9a9026a39ff98796b39db116bac6",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "svc = SVC()\n",
    "svc.fit(x_train, y_train)\n",
    "#y_pred = logreg.predict(x_val)\n",
    "acc_svc = svc.score(x_val, y_val)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6ecd4dc5702b5186be80429679d69c6bb179188f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree Classifier\n",
    "decisiontree = DecisionTreeClassifier()\n",
    "decisiontree.fit(x_train, y_train)\n",
    "#y_pred = decisiontree.predict(x_val)\n",
    "acc_decisiontree = decisiontree.score(x_val, y_val)\n",
    "acc_decisiontree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1e6a9184096698cc60ed6dc6e492ea0708670e89",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Classifier\n",
    "randomforest = RandomForestClassifier()\n",
    "randomforest.fit(x_train, y_train)\n",
    "#y_pred = randomforest.predict(x_val)\n",
    "acc_randomforest = randomforest.score(x_val, y_val)\n",
    "acc_randomforest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b784ae49e743f0a097d32b9f02af865fc61c442",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(x_train, y_train)\n",
    "#y_pred = knn.predict(x_val)\n",
    "acc_knn = knn.score(x_val, y_val)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b72e5184850b1578b84a4c4c0869d555d4da75bb"
   },
   "source": [
    "Based on the outputs above, Decision Tree seems to work the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d18d16a35bccaa0e8216ee4925e04866a9c09a9"
   },
   "source": [
    "# 6. Create a Submission File\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "546d4fe0a67ba22345c723431b104b2530a7c071",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate Predictions\n",
    "prediction = decisiontree.predict(m_test)\n",
    "\n",
    "submission_titanic = pd.DataFrame({ 'PassengerId': PassengerId,\n",
    "                            'Survived': prediction })\n",
    "submission_titanic.to_csv(\"submission_titanic.csv\", index = False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
