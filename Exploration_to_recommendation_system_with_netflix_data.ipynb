{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an initial exploration to recommendation system using the [surprise](http://surpriselib.com/) framework. \n",
    "\n",
    "This notebook will follow the steps of [Netflix - Movie Recommendation](https://www.kaggle.com/laowingkin/netflix-movie-recommendation) and try to replicate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# importing necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from scipy.sparse import csr_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from surprise import Reader, Dataset, SVD, evaluate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1 shape: (24058263, 2)\n",
      "Dataset 2 shape: (26982302, 2)\n",
      "Dataset 3 shape: (22605786, 2)\n",
      "Dataset 4 shape: (26851926, 2)\n"
     ]
    }
   ],
   "source": [
    "# read in datasets\n",
    "\n",
    "df1 = pd.read_csv('combined_data_1.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n",
    "df2 = pd.read_csv('combined_data_2.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n",
    "df3 = pd.read_csv('combined_data_3.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n",
    "df4 = pd.read_csv('combined_data_4.txt', header = None, names = ['Cust_Id', 'Rating'], usecols = [0,1])\n",
    "\n",
    "df1['Rating'] = df1['Rating'].astype(float)\n",
    "df2['Rating'] = df2['Rating'].astype(float)\n",
    "df3['Rating'] = df3['Rating'].astype(float)\n",
    "df4['Rating'] = df4['Rating'].astype(float)\n",
    "\n",
    "print('Dataset 1 shape: {}'.format(df1.shape))\n",
    "print('Dataset 2 shape: {}'.format(df2.shape))\n",
    "print('Dataset 3 shape: {}'.format(df3.shape))\n",
    "print('Dataset 4 shape: {}'.format(df4.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full dataset shape: (100498277, 2)\n",
      "-Dataset examples-\n",
      "           Cust_Id  Rating\n",
      "0               1:     NaN\n",
      "5000000    2560324     4.0\n",
      "10000000   2271935     2.0\n",
      "15000000   1921803     2.0\n",
      "20000000   1933327     3.0\n",
      "25000000   1465002     3.0\n",
      "30000000    961023     4.0\n",
      "35000000   1372532     5.0\n",
      "40000000    854274     5.0\n",
      "45000000    116334     3.0\n",
      "50000000    768483     3.0\n",
      "55000000   1331144     5.0\n",
      "60000000   1609324     2.0\n",
      "65000000   1699240     3.0\n",
      "70000000   1776418     4.0\n",
      "75000000   1643826     5.0\n",
      "80000000    932047     4.0\n",
      "85000000   2292868     4.0\n",
      "90000000    932191     4.0\n",
      "95000000   1815101     3.0\n",
      "100000000   872339     4.0\n"
     ]
    }
   ],
   "source": [
    "# Combine Dataset\n",
    "\n",
    "df = df1\n",
    "df = df1.append(df2)\n",
    "df = df.append(df3)\n",
    "df = df.append(df4)\n",
    "\n",
    "df.index = np.arange(0,len(df))\n",
    "print('Full dataset shape: {}'.format(df.shape))\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b4852981b5ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# numpy approach\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmovie_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmovie_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_np\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmovie_id\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(arr, values, axis)\u001b[0m\n\u001b[1;32m   5164\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5165\u001b[0m         \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5166\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Data Cleaning\n",
    "\n",
    "df_nan = pd.DataFrame(pd.isnull(df.Rating))\n",
    "df_nan = df_nan[df_nan['Rating'] == True]\n",
    "df_nan = df_nan.reset_index()\n",
    "\n",
    "movie_np = []\n",
    "movie_id = 1\n",
    "\n",
    "for i,j in zip(df_nan['index'][1:],df_nan['index'][:-1]):\n",
    "    # numpy approach\n",
    "    temp = np.full((1,i-j-1), movie_id)\n",
    "    movie_np = np.append(movie_np, temp)\n",
    "    movie_id += 1\n",
    "\n",
    "# Account for last record and corresponding length\n",
    "# numpy approach\n",
    "last_record = np.full((1,len(df) - df_nan.iloc[-1, 0] - 1),movie_id)\n",
    "movie_np = np.append(movie_np, last_record)\n",
    "\n",
    "print('Movie numpy: {}'.format(movie_np))\n",
    "print('Length: {}'.format(len(movie_np)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove those Movie ID rows\n",
    "df = df[pd.notnull(df['Rating'])]\n",
    "\n",
    "df['Movie_Id'] = movie_np.astype(int)\n",
    "df['Cust_Id'] = df['Cust_Id'].astype(int)\n",
    "print('-Dataset examples-')\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Slicing\n",
    "# This step is necessary because the data set is extremely large\n",
    "\n",
    "f = ['count','mean']\n",
    "\n",
    "df_movie_summary = df.groupby('Movie_Id')['Rating'].agg(f)\n",
    "df_movie_summary.index = df_movie_summary.index.map(int)\n",
    "movie_benchmark = round(df_movie_summary['count'].quantile(0.8),0)\n",
    "drop_movie_list = df_movie_summary[df_movie_summary['count'] < movie_benchmark].index\n",
    "\n",
    "print('Movie minimum times of review: {}'.format(movie_benchmark))\n",
    "\n",
    "df_cust_summary = df.groupby('Cust_Id')['Rating'].agg(f)\n",
    "df_cust_summary.index = df_cust_summary.index.map(int)\n",
    "cust_benchmark = round(df_cust_summary['count'].quantile(0.8),0)\n",
    "drop_cust_list = df_cust_summary[df_cust_summary['count'] < cust_benchmark].index\n",
    "\n",
    "print('Customer minimum times of review: {}'.format(cust_benchmark))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Check the difference of the datasets\n",
    "print('Original Shape: {}'.format(df.shape))\n",
    "df = df[~df['Movie_Id'].isin(drop_movie_list)]\n",
    "df = df[~df['Cust_Id'].isin(drop_cust_list)]\n",
    "print('After Trim Shape: {}'.format(df.shape))\n",
    "print('-Data Examples-')\n",
    "print(df.iloc[::5000000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pivot the data set and put it into a giant matrix \n",
    "df_p = pd.pivot_table(df,values='Rating',index='Cust_Id',columns='Movie_Id')\n",
    "\n",
    "print(df_p.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the movie mapping file\n",
    "df_title = pd.read_csv('movie_titles.csv', encoding = \"ISO-8859-1\", header = None, names = ['Movie_Id', 'Year', 'Name'])\n",
    "df_title.set_index('Movie_Id', inplace = True)\n",
    "print (df_title.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Recommendation System with Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reader = Reader()\n",
    "\n",
    "# get just top 100K rows for faster run time\n",
    "data = Dataset.load_from_df(df[['Cust_Id', 'Movie_Id', 'Rating']][:100000], reader)\n",
    "data.split(n_folds=3)\n",
    "\n",
    "svd = SVD()\n",
    "evaluate(svd, data, measures=['RMSE', 'MAE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# see what user #785314 liked in the past\n",
    "df_785314 = df[(df['Cust_Id'] == 785314) & (df['Rating'] == 5)]\n",
    "df_785314 = df_785314.set_index('Movie_Id')\n",
    "df_785314 = df_785314.join(df_title)['Name']\n",
    "print(df_785314)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict what user #785314 will like in the future\n",
    "user_785314 = df_title.copy()\n",
    "user_785314 = user_785314.reset_index()\n",
    "user_785314 = user_785314[~user_785314['Movie_Id'].isin(drop_movie_list)]\n",
    "\n",
    "# getting full dataset\n",
    "data = Dataset.load_from_df(df[['Cust_Id', 'Movie_Id', 'Rating']], reader)\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "svd.train(trainset)\n",
    "\n",
    "user_785314['Estimate_Score'] = user_785314['Movie_Id'].apply(lambda x: svd.predict(785314, x).est)\n",
    "\n",
    "user_785314 = user_785314.drop('Movie_Id', axis = 1)\n",
    "\n",
    "user_785314 = user_785314.sort_values('Estimate_Score', ascending=False)\n",
    "print(user_785314.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computational cost for this exercise exceeds the ability of my laptop and it takes a while to run. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
